{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7914a57f-d250-44c9-a4ce-bfd4d43d4f96",
   "metadata": {},
   "source": [
    "**什么是协程？**\n",
    "\n",
    "协程是实现并发编程的一种方式。一说并发，你肯定想到了多线程/多进程模型，没错，多线程/多进程，正是解决并发问题的经典模型之一。最初的互联网世界，多线程/多进程在服务器并发中，起到了举足轻重的作用。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effe57ab-5997-4e8b-b6c7-07a35ae4170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "OK url_1\n",
      "crawling url_2\n",
      "OK url_2\n",
      "crawling url_3\n",
      "OK url_3\n",
      "crawling url_4\n",
      "OK url_4\n",
      "CPU times: user 6.1 ms, sys: 4.92 ms, total: 11 ms\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    time.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "def main(urls):\n",
    "    for url in urls:\n",
    "        crawl_page(url)\n",
    "\n",
    "%time main(['url_1', 'url_2', 'url_3', 'url_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4df757-5a01-476f-bc6c-931631c4f57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "OK url_1\n",
      "crawling url_2\n",
      "OK url_2\n",
      "crawling url_3\n",
      "OK url_3\n",
      "crawling url_4\n",
      "OK url_4\n",
      "CPU times: user 7.79 ms, sys: 3.76 ms, total: 11.5 ms\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "    \n",
    "async def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "async def main(urls):\n",
    "    for url in urls:\n",
    "        await crawl_page(url)\n",
    "\n",
    "%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218de201-595f-46fa-af9a-b6c831fb0957",
   "metadata": {},
   "source": [
    "10秒就对了，还记得上面所说的，await是同步调用，因此，crawl_page(url)在当前的调用结束之前，是不会触发下一次调用的。于是，这个代码效果和上面完全一样了，相当于我们用异步代码写了个同步代码。\n",
    "\n",
    "现在又该怎么办呢？\n",
    "\n",
    "其实很简单，也正是我接下来要讲的协程中的一个重要概念，任务（Task）。老规矩，先看代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19345306-0ee3-45a0-9710-62b308e0b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "crawling url_2\n",
      "crawling url_3\n",
      "crawling url_4\n",
      "OK url_1\n",
      "OK url_2\n",
      "OK url_3\n",
      "OK url_4\n",
      "CPU times: user 7.32 ms, sys: 3.53 ms, total: 10.9 ms\n",
      "Wall time: 4.01 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "async def main(urls):\n",
    "    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]\n",
    "    for task in tasks:\n",
    "        await task\n",
    "\n",
    "%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d45ac354-6ec3-4d48-9b4d-82612c851a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "crawling url_2\n",
      "crawling url_3\n",
      "crawling url_4\n",
      "OK url_1\n",
      "OK url_2\n",
      "OK url_3\n",
      "OK url_4\n",
      "CPU times: user 6.83 ms, sys: 4.67 ms, total: 11.5 ms\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "    \n",
    "async def main(urls):\n",
    "    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]\n",
    "    await asyncio.gather(*tasks)\n",
    "    \n",
    "%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bd0ab41-a6d8-4072-b98d-516e501cd37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before await\n",
      "CPU times: user 905 µs, sys: 312 µs, total: 1.22 ms\n",
      "Wall time: 1.23 ms\n",
      "worker_2 start\n",
      "worker_1 start\n",
      "worker_1 end\n",
      "worker_2 end\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def worker_1():\n",
    "    print('worker_1 start')\n",
    "    await asyncio.sleep(1)\n",
    "    print('worker_1 end')\n",
    "\n",
    "async def worker_2():\n",
    "    print('worker_2 start')\n",
    "    await asyncio.sleep(2)\n",
    "    print('worker_2 end')\n",
    "\n",
    "async def main():\n",
    "    task1 = asyncio.create_task(worker_1())\n",
    "    task2 = asyncio.create_task(worker_2())\n",
    "    print('before await')\n",
    "    await task1\n",
    "    print('awaited worker_1')\n",
    "    await task2\n",
    "    print('awaited worker_2')\n",
    "\n",
    "%time asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1375f2-d5bd-442a-88ad-5760e4dfbf02",
   "metadata": {},
   "source": [
    "before await\n",
    "worker_1 start\n",
    "worker_2 start\n",
    "worker_1 end\n",
    "awaited worker_1\n",
    "worker_2 end\n",
    "awaited worker_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ee12355-f8fc-4e4b-ad77-5e5c2f00fb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, ZeroDivisionError('division by zero'), CancelledError('')]\n",
      "CPU times: user 2.99 ms, sys: 3.05 ms, total: 6.03 ms\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def worker_1():\n",
    "    await asyncio.sleep(1)\n",
    "    return 1\n",
    "\n",
    "async def worker_2():\n",
    "    await asyncio.sleep(2)\n",
    "    return 2 / 0\n",
    "\n",
    "async def worker_3():\n",
    "    await asyncio.sleep(3)\n",
    "    return 3\n",
    "\n",
    "async def main():\n",
    "    task_1 = asyncio.create_task(worker_1())\n",
    "    task_2 = asyncio.create_task(worker_2())\n",
    "    task_3 = asyncio.create_task(worker_3())\n",
    "    \n",
    "    await asyncio.sleep(2)\n",
    "    task_3.cancel()\n",
    "    \n",
    "    res = await asyncio.gather(task_1, task_2, task_3, return_exceptions=True)\n",
    "    print(res)\n",
    "\n",
    "%time asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a9685db-d16f-4135-a45a-183d90620dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producer_1 put a value: 9\n",
      "producer_2 put a value: 4\n",
      "consumer_1 get a value: 9\n",
      "consumer_2 get a value: 4\n",
      "producer_1 put a value: 2\n",
      "producer_2 put a value: 7\n",
      "consumer_1 get a value: 2\n",
      "consumer_2 get a value: 7\n",
      "producer_1 put a value: 9\n",
      "producer_2 put a value: 4\n",
      "consumer_1 get a value: 9\n",
      "consumer_2 get a value: 4\n",
      "producer_1 put a value: 10\n",
      "producer_2 put a value: 3\n",
      "consumer_1 get a value: 10\n",
      "consumer_2 get a value: 3\n",
      "producer_1 put a value: 7\n",
      "producer_2 put a value: 10\n",
      "consumer_1 get a value: 7\n",
      "consumer_2 get a value: 10\n",
      "CPU times: user 12.8 ms, sys: 6.31 ms, total: 19.1 ms\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def consumer(queue, id):\n",
    "    while True:\n",
    "        val = await queue.get()\n",
    "        print('{} get a value: {}'.format(id, val))\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "async def producer(queue, id):\n",
    "    for i in range(5):\n",
    "        val = random.randint(1, 10)\n",
    "        await queue.put(val)\n",
    "        print('{} put a value: {}'.format(id, val))\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "async def main():\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    consumer_1 = asyncio.create_task(consumer(queue, 'consumer_1'))\n",
    "    consumer_2 = asyncio.create_task(consumer(queue, 'consumer_2'))\n",
    "    \n",
    "    producer_1 = asyncio.create_task(producer(queue, 'producer_1'))\n",
    "    producer_2 = asyncio.create_task(producer(queue, 'producer_2'))\n",
    "    \n",
    "    await asyncio.sleep(10)\n",
    "    consumer_1.cancel()\n",
    "    consumer_2.cancel()\n",
    "    \n",
    "    await asyncio.gather(consumer_1, consumer_2, producer_1, producer_2, return_exceptions=True)\n",
    "    \n",
    "%time asyncio.run(main())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de73de04-9871-4bdd-9d00-60722bfc61c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我要我们在一起 05月20日上映 https://movie.douban.com/subject/25881778/?from=playing_poster\n",
      "唐顿庄园2 05月20日上映 https://movie.douban.com/subject/35008440/?from=playing_poster\n",
      "爱犬奇缘 05月20日上映 https://movie.douban.com/subject/35440759/?from=playing_poster\n",
      "异兽 05月20日上映 https://movie.douban.com/subject/35817963/?from=playing_poster\n",
      "黎乡遇见你 05月20日上映 https://movie.douban.com/subject/35859238/?from=playing_poster\n",
      "牧民省长尕布龙 05月20日上映 https://movie.douban.com/subject/35630352/?from=playing_poster\n",
      "青春是首歌 05月27日上映 https://movie.douban.com/subject/35295545/?from=playing_poster\n",
      "盒子的秘密 05月27日上映 https://movie.douban.com/subject/35561858/?from=playing_poster\n",
      "刿心剑 05月28日上映 https://movie.douban.com/subject/35352814/?from=playing_poster\n",
      "魔法鼠乐园 06月01日上映 https://movie.douban.com/subject/30487738/?from=playing_poster\n",
      "CPU times: user 267 ms, sys: 79.4 ms, total: 346 ms\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.113 Safari/537.36',\n",
    "    'Referer':'https://time.geekbang.org/column/article/101855',\n",
    "    'Connection':'keep-alive'\n",
    "}\n",
    "\n",
    "\n",
    "def main():\n",
    "    url = \"https://movie.douban.com/cinema/nowplaying/shanghai\"\n",
    "    init_page = requests.get(url, headers=headers).content\n",
    "    init_soup = BeautifulSoup(init_page, 'lxml')\n",
    "    \n",
    "    all_movies = init_soup.find('div', id=\"upcoming\")\n",
    "    for each_movie in all_movies.find_all('li', class_=\"list-item\"):\n",
    "        movie_name = each_movie['data-title']\n",
    "        movie_date = each_movie.find('li', class_='release-date').string.strip()\n",
    "        movie_src = each_movie.find('li', class_='stitle').a['href']\n",
    "        print('{} {} {}'.format(movie_name, movie_date, movie_src))\n",
    "\n",
    "%time main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f44893f5-1f00-4fad-9b9c-8935d1bb061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.113 Safari/537.36',\n",
    "    'Referer':'https://time.geekbang.org/column/article/101855',\n",
    "    'Connection':'keep-alive'\n",
    "}\n",
    "\n",
    "url = \"https://movie.douban.com/cinema/nowplaying/shanghai\"\n",
    "\n",
    "async def fetch_content(url):\n",
    "    async with aiohttp.ClientSession(\n",
    "    headers=headers, connector=aiohttp.TCPConnector(ssl=False)) as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "async def main():\n",
    "    init_page = await fetch_content(url) \n",
    "    init_soup = BeautifulSoup(init_page, 'lxml')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c74bd1-f311-427b-b315-9fac9d01ed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
